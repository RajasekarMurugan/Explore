{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd5BOmHQmVTP51W3rJwXo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajasekarMurugan/Explore/blob/main/LangChain_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain-google-genai google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hFVEWxIac2n",
        "outputId": "4e66612e-d84d-499d-9f4e-3998885e04c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.2/490.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompting Strategies:\n",
        "\n",
        "  - Zero Shot Prompting\n",
        "  - Few Shot Prompting\n",
        "  - Chain-of-Thought prompting\n",
        "  "
      ],
      "metadata": {
        "id": "lJTl1DXMcgE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
      ],
      "metadata": {
        "id": "mAyBd8lgapav"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up an environement to connect with Google Gemini\n",
        "os.environ['GOOGLE_API_KEY'] = \"AIzaSyDrr9oxyZiQ9MqcHLZwWUDRAWuCVM0C2T0\""
      ],
      "metadata": {
        "id": "cD479U52b5HZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini LLM,Below models are avialable\n",
        "  - gemini-2.5-flash\n",
        "  - gemini-2.5-flash-lite\n",
        "  - gemini-3-flash\n",
        "  - gemma-3-27b\n",
        "  .."
      ],
      "metadata": {
        "id": "BLNjOG2Kes_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash-lite\", temperature = 0.9)"
      ],
      "metadata": {
        "id": "oP2r1dk4d2Nb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs have 'System Messsage' & 'user Message'\n",
        "  - System Message - Manages the persona of the LLM\n",
        "  - User Messages - Manages user prompt"
      ],
      "metadata": {
        "id": "fFUDt8nLgQlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Shot prompting using gemini llm and langchain for marketting Domain\n",
        "# Use case - product positioning for an AI based product\n",
        "\n",
        "zero_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a senior marketting strategist\"), # persona attached to the LLM\n",
        "    (\"human\", \"\"\"create a concise product position statement for an AI powered resume screening platform,\n",
        "    The Target audience for this project are HR-leaders from mid sized company,\n",
        "    Ensure the response is in professional tone and is within 60 words\"\"\") # User Query\n",
        "])"
      ],
      "metadata": {
        "id": "XR-B2PvBerFp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(zero_shot_prompt.format_messages())\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r97e8YFTh59J",
        "outputId": "4b1cc798-06a6-4503-d945-677d3778532a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For HR leaders in mid-sized companies seeking efficiency, our AI-powered resume screening platform offers **unbiased, rapid talent identification**. Unlike manual review, we deliver faster, more accurate candidate shortlisting, empowering you to build stronger teams and drive business growth with confidence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain-of-Thought prompting using Gemini LLM and langchain for BFSI domain\n",
        "# User case - Loan eligibility assessment\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \" YOu are a credit risk analyst at a commercial Bank\"),\n",
        "    (\"user\", \"\"\"\n",
        "    Assess the loan eligibility using the following structured evaluation method provoided below as reference\n",
        "    Applicant details:\n",
        "    - Credit score : 700\n",
        "    - Monthly income : 75,000 INR\n",
        "    - Existing EMI obligations : 18,000 INR\n",
        "    - Loan Amount requested : 10,00,000 INR\n",
        "\n",
        "    Evaluation Steps:\n",
        "    - Credit worthiness assessment\n",
        "    - affordability analysis\n",
        "    - Risk considerations\n",
        "    - Final eligibility decision\n",
        "\n",
        "    Output format:\n",
        "    - Clear section for header\n",
        "    - Bullet points for each section\n",
        "    - final decision clearly stated with reason\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "Bxl1fg_7iEbZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.invoke(zero_shot_prompt.format_messages())\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFerSNOEo7Dj",
        "outputId": "4f9e2bc8-4bdc-4a9e-eee6-b45f8e1522a1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For HR leaders at mid-sized companies, our AI-powered resume screening platform is the intelligent solution that transforms hiring. Unlike manual review, we deliver faster, more accurate candidate identification, ensuring you connect with top talent efficiently and build stronger teams, reducing time-to-hire and improving candidate quality.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glb9aKfdo-H0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}